{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0760496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon April 29 13:25:11 2020\n",
    "\n",
    "@author: rfuchs\n",
    "\"\"\"\n",
    "\n",
    "import os \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from gower import gower_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "from MIAMI import MIAMI\n",
    "from init_params import dim_reduce_init\n",
    "from data_preprocessing import compute_nj\n",
    "\n",
    "from shapely.geometry import Polygon as polygon\n",
    "\n",
    "import autograd.numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfdae60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with 45221 observations!!!!\n"
     ]
    }
   ],
   "source": [
    "res_folder = 'MIAMI/Results/Adult/'\n",
    "\n",
    "if not os.path.exists(res_folder):\n",
    "    os.makedirs(res_folder)\n",
    "#===========================================#\n",
    "# Model Hyper-parameters\n",
    "#===========================================#\n",
    "\n",
    "n_clusters = 4\n",
    "r = np.array([2, 1])\n",
    "k = [4]\n",
    "\n",
    "seed = 1\n",
    "init_seed = 2\n",
    "    \n",
    "# !!! Changed eps\n",
    "eps = 1E-02\n",
    "it = 4\n",
    "maxstep = 100\n",
    "        \n",
    "\n",
    "var_distrib = np.array(['continuous', 'categorical', 'continuous',\\\n",
    "                        'ordinal', 'categorical', 'categorical', 'categorical',\\\n",
    "                        'categorical', 'bernoulli', 'ordinal', 'ordinal',\\\n",
    "                        'continuous', 'categorical', 'bernoulli']) \n",
    "\n",
    "# Plotting utilities\n",
    "varnames = np.array(['age', 'workclass', 'fnlwgt',\\\n",
    "            'education.num', 'marital.status', 'occupation', 'relationship',\\\n",
    "            'race', 'sex', 'capital.gain', 'capital.loss',\\\n",
    "            'hours.per.week', 'native.country', 'income'])\n",
    "\n",
    "    \n",
    "dtypes_dict = {'continuous': float, 'categorical': str, 'ordinal': int,\\\n",
    "              'bernoulli': int, 'binomial': int}\n",
    "    \n",
    "    \n",
    "\n",
    "#===========================================#\n",
    "# Importing data\n",
    "#===========================================#\n",
    "\n",
    "inf_nb = 1E12\n",
    "nb_pobs = 200\n",
    "\n",
    "\n",
    "# acceptance_rate =\n",
    "le_dict = {}\n",
    "\n",
    "train_filepath = res_folder + 'adult.csv'\n",
    "\n",
    "\n",
    "train = pd.read_csv(train_filepath, sep = ',')\n",
    "train = train.infer_objects()\n",
    "\n",
    "\n",
    "\n",
    "# Delete the missing values \n",
    "train = train.loc[~(train == '?').any(axis=1)]\n",
    "\n",
    "NUMBER_OBSERVATIONS = -1\n",
    "train = train.iloc[:NUMBER_OBSERVATIONS, :]\n",
    "\n",
    "\n",
    "numobs = len(train)\n",
    "print(\"Running with\", numobs, \"observations!!!!\")\n",
    "# !!! Hack to remove\n",
    "del(train['education'])\n",
    "p = train.shape[1]\n",
    "\n",
    "new_names_dict = dict(zip(train.columns, varnames))\n",
    "\n",
    "train = train.rename(columns=new_names_dict)\n",
    "\n",
    "# Find the indices of the continuous features\n",
    "continuous_indices = np.where(var_distrib == 'continuous')[0]\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the continuous features\n",
    "train.iloc[:, continuous_indices] = scaler.fit_transform(train.iloc[:, continuous_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f88a84bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train[\"native.country\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83983ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Gower\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#***************************************************************************\n",
    "# Invert the order of the columns so that age is no more the first bernoulli\n",
    "#***************************************************************************\n",
    "'''\n",
    "train[['age', 'workclass', 'fnlwgt', 'education.num', 'marital.status',\n",
    "        'occupation', 'relationship', 'race', 'capital.gain',\n",
    "        'capital.loss', 'hours.per.week', 'native.country', 'income', 'sex']]\n",
    "\n",
    "\n",
    "var_distrib = np.array(['continuous', 'categorical', 'continuous',\\\n",
    "            'ordinal', 'categorical', 'categorical', 'categorical',\\\n",
    "            'categorical', 'ordinal', 'ordinal',\\\n",
    "            'continuous', 'categorical', 'bernoulli', 'bernoulli']) \n",
    "'''\n",
    "                    \n",
    "p_new = len(var_distrib)\n",
    "cat_features = np.logical_or(var_distrib == 'categorical', var_distrib == 'ordinal')\n",
    "\n",
    "\n",
    "#*****************************************************************\n",
    "# Formating the data\n",
    "#*****************************************************************\n",
    "                \n",
    "# Encode categorical datas\n",
    "for col_idx, colname in enumerate(train.columns):\n",
    "    if var_distrib[col_idx] == 'categorical': \n",
    "        le = LabelEncoder()\n",
    "\n",
    "        # Convert them into numerical values               \n",
    "        train[colname] = le.fit_transform(train[colname]) \n",
    "        le_dict[colname] = deepcopy(le)\n",
    "\n",
    "    \n",
    "# Encode binary data\n",
    "for col_idx, colname in enumerate(train.columns):\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    if var_distrib[col_idx] == 'bernoulli': \n",
    "        train[colname] = le.fit_transform(train[colname])\n",
    "        le_dict[colname] = deepcopy(le)\n",
    "\n",
    "# Encode ordinal data, modalities have been sorted (at best)\n",
    "            \n",
    "ord_le = LabelEncoder()\n",
    "train['education.num'] = ord_le.fit_transform(train['education.num'])\n",
    "le_dict['education.num'] = deepcopy(ord_le)\n",
    "\n",
    "# Encode capital.gain and capital.loss and capital.gain as ordinal variables\n",
    "for col in ['capital.gain', 'capital.loss']:\n",
    "    le = LabelEncoder()\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    le_dict[col] = deepcopy(le)\n",
    "\n",
    "nj, nj_bin, nj_ord, nj_categ = compute_nj(train, var_distrib)\n",
    "nb_cont = np.sum(var_distrib == 'continuous')        \n",
    "        \n",
    "# Feature category (cf)\n",
    "dtype = {train.columns[j]: dtypes_dict[var_distrib[j]] for j in range(p)}\n",
    "\n",
    "train = train.astype(dtype, copy=True)\n",
    "numobs = len(train)\n",
    "\n",
    "print(\"Computing Gower\")\n",
    "# Defining distances over the features\n",
    "dm = gower_matrix(train, cat_features = cat_features) \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5afd4480",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_design = \"none\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce57749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*****************************************************************\n",
    "# Sampling rules\n",
    "#*****************************************************************    \n",
    "authorized_ranges = np.expand_dims(np.stack([[-np.inf,np.inf] for var in var_distrib]).T, 1)\n",
    "\n",
    "if sub_design == 'bivariate':\n",
    "    # Want to sample only women of more than 60 years old\n",
    "    authorized_ranges[:,0, 0] = [60, 100]  # Of more than 60 years old\n",
    "\n",
    "    # Keep only women\n",
    "    sex_idx = np.argmax(varnames == 'sex')\n",
    "    women_idx = np.argmax(le_dict['sex'].classes_ == 'Female')\n",
    "    authorized_ranges[:,0, sex_idx] = [women_idx, women_idx] # Only women\n",
    "    \n",
    "elif sub_design == 'trivariate':\n",
    "    # Want to sample only women of more than 60 years old that are widowed\n",
    "    authorized_ranges[:,0, 0] = [60, 100]  # Of more than 60 years old\n",
    "    \n",
    "    # Keep only women\n",
    "    sex_idx = np.argmax(varnames == 'sex')\n",
    "    women_idx = np.argmax(le_dict['sex'].classes_ == 'Female')\n",
    "    authorized_ranges[:,0, sex_idx] = [women_idx, women_idx] # Only women\n",
    "\n",
    "    # Keep only widows\n",
    "    marital_idx = np.argmax(varnames == 'marital.status')                \n",
    "    widowed_idx = np.argmax(le_dict['marital.status'].classes_ == 'Widowed')\n",
    "    authorized_ranges[:,0, marital_idx] = [widowed_idx, widowed_idx] # Only widowed\n",
    "else:\n",
    "    authorized_ranges = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4a79837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run MIAMI\n",
      "(45221, 2)\n",
      "(17, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/panagiotou/Desktop/M1DGMM/bevel/linear_ordinal_regression.py:231: RuntimeWarning: divide by zero encountered in log\n",
      "  return - 1.0 * np.sum(np.log(self.link(z_plus) - self.link(z_minus)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45221, 2)\n",
      "(122, 122)\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#*****************************************************************\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Run MIAMI\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#*****************************************************************\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun MIAMI\u001b[39m\u001b[38;5;124m\"\u001b[39m)    \n\u001b[0;32m----> 6\u001b[0m init \u001b[38;5;241m=\u001b[39m \u001b[43mdim_reduce_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_distrib\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                \u001b[49m\u001b[43muse_famd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m out \u001b[38;5;241m=\u001b[39m MIAMI(train, n_clusters, r, k, init, var_distrib, nj, authorized_ranges, nb_pobs, it,\\\n\u001b[1;32m     11\u001b[0m                 eps, maxstep, seed, perform_selec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, dm \u001b[38;5;241m=\u001b[39m dm, max_patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/M1DGMM/init_params.py:283\u001b[0m, in \u001b[0;36mdim_reduce_init\u001b[0;34m(y, n_clusters, k, r, nj, var_distrib, use_famd, seed)\u001b[0m\n\u001b[1;32m    280\u001b[0m yj \u001b[38;5;241m=\u001b[39m y_ord[:,j]\n\u001b[1;32m    282\u001b[0m ol \u001b[38;5;241m=\u001b[39m OrderedLogit()\n\u001b[0;32m--> 283\u001b[0m \u001b[43mol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m## Identifiability of ordinal coefficients\u001b[39;00m\n\u001b[1;32m    286\u001b[0m beta_j \u001b[38;5;241m=\u001b[39m (ol\u001b[38;5;241m.\u001b[39mbeta_\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, r[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m@\u001b[39m AT[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[0;32m~/Desktop/M1DGMM/bevel/linear_ordinal_regression.py:78\u001b[0m, in \u001b[0;36mLinearOrdinalRegression.fit\u001b[0;34m(self, X, y, maxfun, maxiter, epsilon)\u001b[0m\n\u001b[1;32m     75\u001b[0m gamma[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m gamma[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m X_mean\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(gamma)\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mse_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_standard_errors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp_values_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_p_values()\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_score(X_data, y_data)\n",
      "File \u001b[0;32m~/Desktop/M1DGMM/bevel/linear_ordinal_regression.py:260\u001b[0m, in \u001b[0;36mLinearOrdinalRegression._compute_standard_errors\u001b[0;34m(self, coefficients, X_data, y_data)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28mprint\u001b[39m(H\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mdiagonal(P\u001b[38;5;241m.\u001b[39mdot(\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mdot(P\u001b[38;5;241m.\u001b[39mT)))\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/M1DGMM/venv/lib/python3.10/site-packages/numpy/linalg/linalg.py:538\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    536\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    537\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> 538\u001b[0m ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/Desktop/M1DGMM/venv/lib/python3.10/site-packages/numpy/linalg/linalg.py:89\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "#*****************************************************************\n",
    "# Run MIAMI\n",
    "#*****************************************************************\n",
    "\n",
    "print(\"Run MIAMI\")    \n",
    "init = dim_reduce_init(train, n_clusters, k, r, nj, var_distrib, seed = None,\\\n",
    "                                use_famd=True)\n",
    "\n",
    "print(\"Training\")\n",
    "out = MIAMI(train, n_clusters, r, k, init, var_distrib, nj, authorized_ranges, nb_pobs, it,\\\n",
    "                eps, maxstep, seed, perform_selec = False, dm = dm, max_patience = 0)\n",
    "print('MIAMI has kept one observation over', round(1 / out['share_kept_pseudo_obs']),\\\n",
    "        'observations generated')\n",
    "    \n",
    "acceptance_rate = out['share_kept_pseudo_obs']\n",
    "print(acceptance_rate)\n",
    "pred = pd.DataFrame(out['y_all'], columns = train.columns) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89487e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================================\n",
    "# Inverse transform the datasets\n",
    "#================================================================\n",
    "\n",
    "for j, colname in enumerate(train.columns):\n",
    "    if colname in le_dict.keys():\n",
    "        pred[colname] = le_dict[colname].inverse_transform(pred[colname].astype(int))\n",
    "    \n",
    "pred.loc[:, var_distrib == 'continuous'] = pred.loc[:, var_distrib == 'continuous'].round(0)\n",
    "\n",
    "print(\"Saved to\", res_folder + 'preds.csv')\n",
    "# Store the predictions\n",
    "pred.to_csv(res_folder + 'preds.csv', index = False)\n",
    "#break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7946d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a369435",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acceptance_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8629e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = out[\"zz\"]\n",
    "\n",
    "# z2 = np.vstack([zzz for zzz in zz if len(zzz) >0])\n",
    "# plt.scatter(z2[:,0], z2[:,1])\n",
    "# x1,y1 = polygon.exterior.coords.xy\n",
    "# plt.plot(x1,y1)\n",
    "\n",
    "\n",
    "# Compare woman, 60+ y.o and people presenting both modalities\n",
    "zz = np.concatenate(out['zz'])\n",
    "\n",
    "woman_idx = train['sex'] == 0\n",
    "age_idx = train['age'] >= 60\n",
    "bivariate_idx = woman_idx & age_idx\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (9, 9))\n",
    "ax.scatter(out['Ez.y'][woman_idx,0], out['Ez.y'][woman_idx,1], c='blue', label = '(Train set) women')\n",
    "ax.scatter(out['Ez.y'][age_idx,0], out['Ez.y'][age_idx,1], c='red', label = '(Train set) 60+ years old')\n",
    "ax.scatter(zz[:,0], zz[:,1], c='darkgreen', label = '(MIAMI) women 60+ y.o.')\n",
    "#plt.title('Latent representation of women and 60+ y.o. individuals from the train set and generated by MIAMI')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3826320",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = out[\"zz\"]\n",
    "\n",
    "# z2 = np.vstack([zzz for zzz in zz if len(zzz) >0])\n",
    "# plt.scatter(z2[:,0], z2[:,1])\n",
    "# x1,y1 = polygon.exterior.coords.xy\n",
    "# plt.plot(x1,y1)\n",
    "\n",
    "\n",
    "# Compare woman, 60+ y.o and people presenting both modalities\n",
    "zz = np.concatenate(out['zz'])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (9, 9))\n",
    "ax.scatter(out['Ez.y'][:,0], out['Ez.y'][:,1], c='blue', label = '(Train set)')\n",
    "ax.scatter(zz[:,0], zz[:,1], c='darkgreen', label = '(MIAMI) synthetic')\n",
    "#plt.title('Latent representation of women and 60+ y.o. individuals from the train set and generated by MIAMI')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff101824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3de0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = out[\"zz\"]\n",
    "\n",
    "# z2 = np.vstack([zzz for zzz in zz if len(zzz) >0])\n",
    "# plt.scatter(z2[:,0], z2[:,1])\n",
    "# x1,y1 = polygon.exterior.coords.xy\n",
    "# plt.plot(x1,y1)\n",
    "\n",
    "feature = \"sex\"\n",
    "labels_real = le_dict[feature].inverse_transform(train[feature])\n",
    "\n",
    "unique_labels = set(labels_real)\n",
    "# Compare woman, 60+ y.o and people presenting both modalities\n",
    "zz = np.concatenate(out['zz'])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (9, 9))\n",
    "\n",
    "scatt = ax.scatter(out['Ez.y'][:,0], out['Ez.y'][:,1], c=train[feature])\n",
    "#plt.title('Latent representation of women and 60+ y.o. individuals from the train set and generated by MIAMI')\n",
    "# Create legend\n",
    "handles, labels = scatt.legend_elements()\n",
    "legend1 = ax.legend(handles, labels_real, loc=\"lower left\", title=\"Labels\")\n",
    "ax.add_artist(legend1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee877cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
